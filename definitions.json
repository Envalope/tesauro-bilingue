[
    {
        "id": "LAW001",
        "term_en": "AI Act",
        "term_it": "AI Act",
        "definition_en": "European Union regulation governing the development, deployment, and use of artificial intelligence systems.",
        "definition_it": "Regolamento dell'Unione Europea che disciplina lo sviluppo, l'implementazione e l'uso dei sistemi di intelligenza artificiale.",
        "relations": {
            "broader": [
                "AI Governance"
            ],
            "narrower": [
                "High-Risk AI Systems"
            ],
            "related": [
                "Ethical Guidelines"
            ]
        },
        "variants": [
            "Regulation 1689/2024"
        ],
        "sources": [
            {
                "name": "Reg. UE 1689/2024",
                "url": "https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689",
                "article": "Art. 1-5"
            }
        ],
        "area_semantica": "normativa-giuridica"
    },
    {
        "id": "LAW002",
        "term_en": "High-Risk AI System",
        "term_it": "Sistema IA ad Alto Rischio",
        "definition_en": "AI systems that have significant impact on people's safety or fundamental rights and are subject to stricter requirements.",
        "definition_it": "Sistemi di IA che hanno un impatto significativo sulla sicurezza delle persone o sui diritti fondamentali e sono soggetti a requisiti più severi.",
        "relations": {
            "broader": [
                "AI Act"
            ],
            "narrower": [
                "Medical AI",
                "Autonomous Vehicle AI"
            ],
            "related": [
                "Risk Assessment"
            ]
        },
        "variants": [
            "Critical AI System"
        ],
        "sources": [
            {
                "name": "AI Act 1689/2024",
                "url": "https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689",
                "article": "Art. 6-12"
            },
            {
                "name": "NIST AI RMF",
                "url": "https://www.nist.gov/ai-risk-management-framework",
                "article": ""
            }
        ],
        "area_semantica": "normativa-giuridica"
    },
    {
        "id": "LAW003",
        "term_en": "Data Protection",
        "term_it": "Protezione dei dati",
        "definition_en": "Principles and rules to ensure that AI systems respect privacy and personal data rights.",
        "definition_it": "Principi e regole per garantire che i sistemi di IA rispettino la privacy e i diritti sui dati personali.",
        "relations": {
            "broader": [
                "AI Governance"
            ],
            "narrower": [
                "GDPR Compliance"
            ],
            "related": [
                "High-Risk AI System"
            ]
        },
        "variants": [
            "Privacy Compliance"
        ],
        "sources": [
            {
                "name": "GDPR 679/2016",
                "url": "https://eur-lex.europa.eu/eli/reg/2016/679/oj",
                "article": "Art. 5-6"
            },
            {
                "name": "AI Act 1689/2024",
                "url": "https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689",
                "article": "Art. 10-12"
            }
        ],
        "area_semantica": "normativa-giuridica"
    },
    {
        "id": "LAW004",
        "term_en": "Regulatory Sandboxes",
        "term_it": "Banchi di prova regolatori",
        "definition_en": "Controlled environments allowing AI developers to test products under regulatory supervision.",
        "definition_it": "Ambienti controllati che consentono agli sviluppatori di IA di testare prodotti sotto supervisione normativa.",
        "relations": {
            "broader": [
                "AI Act"
            ],
            "narrower": [],
            "related": [
                "High-Risk AI System"
            ]
        },
        "variants": [
            "Testing Sandbox"
        ],
        "sources": [
            {
                "name": "AI Act 1689/2024",
                "url": "https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689",
                "article": "Art. 53-56"
            }
        ],
        "area_semantica": "normativa-giuridica"
    },
    {
        "id": "LAW005",
        "term_en": "Risk Assessment",
        "term_it": "Valutazione del rischio",
        "definition_en": "Process of identifying and evaluating potential harms of AI systems in compliance with legal requirements.",
        "definition_it": "Processo di identificazione e valutazione dei potenziali danni dei sistemi IA in conformità ai requisiti legali.",
        "relations": {
            "broader": [
                "High-Risk AI System"
            ],
            "narrower": [],
            "related": [
                "AI Act"
            ]
        },
        "variants": [
            "AI Risk Evaluation"
        ],
        "sources": [
            {
                "name": "AI Act 1689/2024",
                "url": "https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689",
                "article": "Art. 19-22"
            }
        ],
        "area_semantica": "normativa-giuridica"
    },
    {
        "id": "LAW006",
        "term_en": "Conformity Assessment",
        "term_it": "Valutazione di conformità",
        "definition_en": "Verification that AI systems meet the requirements set by law before being deployed on the market.",
        "definition_it": "Verifica che i sistemi IA rispettino i requisiti stabiliti dalla legge prima della messa in commercio.",
        "relations": {
            "broader": [
                "High-Risk AI System"
            ],
            "narrower": [],
            "related": [
                "Risk Assessment"
            ]
        },
        "variants": [
            "Compliance Check"
        ],
        "sources": [
            {
                "name": "AI Act 1689/2024",
                "url": "https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689",
                "article": "Art. 17-18"
            }
        ],
        "area_semantica": "normativa-giuridica"
    },
    {
        "id": "LAW007",
        "term_en": "AI Liability",
        "term_it": "Responsabilità IA",
        "definition_en": "Legal principles determining who is responsible when AI systems cause harm.",
        "definition_it": "Principi giuridici che determinano chi è responsabile quando i sistemi IA causano danni.",
        "relations": {
            "broader": [
                "AI Act"
            ],
            "narrower": [],
            "related": [
                "Data Protection"
            ]
        },
        "variants": [
            "Liability Rules"
        ],
        "sources": [
            {
                "name": "AI Act 1689/2024",
                "url": "https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689",
                "article": "Art. 75-80"
            }
        ],
        "area_semantica": "normativa-giuridica"
    },
    {
        "id": "LAW008",
        "term_en": "Transparency Obligations",
        "term_it": "Obblighi di trasparenza",
        "definition_en": "Requirements for AI systems to provide clear information on functionality and decision-making.",
        "definition_it": "Requisiti per i sistemi IA di fornire informazioni chiare su funzionalità e processi decisionali.",
        "relations": {
            "broader": [
                "AI Act"
            ],
            "narrower": [
                "Explainability"
            ],
            "related": [
                "Ethical Guidelines"
            ]
        },
        "variants": [
            "Disclosure Duties"
        ],
        "sources": [
            {
                "name": "AI Act 1689/2024",
                "url": "https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689",
                "article": "Art. 13-16"
            }
        ],
        "area_semantica": "normativa-giuridica"
    },
    {
        "id": "LAW009",
        "term_en": "Human Oversight",
        "term_it": "Sorveglianza umana",
        "definition_en": "Obligation to ensure human monitoring of AI systems to prevent or mitigate risks.",
        "definition_it": "Obbligo di garantire il monitoraggio umano dei sistemi IA per prevenire o mitigare i rischi.",
        "relations": {
            "broader": [
                "High-Risk AI System"
            ],
            "narrower": [],
            "related": [
                "AI Liability"
            ]
        },
        "variants": [
            "Human-in-the-loop"
        ],
        "sources": [
            {
                "name": "AI Act 1689/2024",
                "url": "https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689",
                "article": "Art. 14-15"
            }
        ],
        "area_semantica": "normativa-giuridica"
    },
    {
        "id": "LAW010",
        "term_en": "Market Surveillance",
        "term_it": "Sorveglianza del mercato",
        "definition_en": "Processes and authorities responsible for ensuring AI systems comply with legal standards after deployment.",
        "definition_it": "Processi e autorità responsabili di garantire che i sistemi IA rispettino gli standard legali dopo la loro immissione sul mercato.",
        "relations": {
            "broader": [
                "AI Act"
            ],
            "narrower": [],
            "related": [
                "Conformity Assessment"
            ]
        },
        "variants": [
            "Regulatory Oversight"
        ],
        "sources": [
            {
                "name": "AI Act 1689/2024",
                "url": "https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689",
                "article": "Art. 57-60"
            }
        ],
        "area_semantica": "normativa-giuridica"
    },
    {
        "id": "TECH001",
        "term_en": "Machine Learning",
        "term_it": "Apprendimento Automatico",
        "definition_en": "A subset of AI where systems improve performance through experience, data, and feedback without being explicitly programmed.",
        "definition_it": "Un sottoinsieme di IA in cui i sistemi migliorano le prestazioni attraverso l'esperienza senza essere programmati esplicitamente.",
        "relations": {
            "broader": [
                "Artificial Intelligence"
            ],
            "narrower": [
                "Supervised Learning",
                "Unsupervised Learning"
            ],
            "related": [
                "Deep Learning"
            ]
        },
        "variants": [
            "ML"
        ],
        "sources": [
            {
                "name": "ISO/IEC 22989:2022",
                "url": "https://www.iso.org/standard/77465.html"
            }
        ],
        "area_semantica": "tecnico-operativa"
    },
    {
        "id": "TECH002",
        "term_en": "Deep Learning",
        "term_it": "Apprendimento Profondo",
        "definition_en": "A class of machine learning using neural networks with multiple layers to model complex patterns.",
        "definition_it": "Una classe di apprendimento automatico che utilizza reti neurali con più strati per modellare schemi complessi.",
        "relations": {
            "broader": [
                "Machine Learning"
            ],
            "narrower": [
                "CNN",
                "RNN"
            ],
            "related": [
                "AI Systems"
            ]
        },
        "variants": [
            "DL"
        ],
        "sources": [
            {
                "name": "ISO/IEC 22989:2022",
                "url": "https://www.iso.org/standard/77465.html"
            }
        ],
        "area_semantica": "tecnico-operativa"
    },
    {
        "id": "TECH003",
        "term_en": "Natural Language Processing",
        "term_it": "Elaborazione del Linguaggio Naturale",
        "definition_en": "AI techniques to enable machines to understand, interpret, and generate human language.",
        "definition_it": "Tecniche di IA per consentire alle macchine di comprendere, interpretare e generare il linguaggio umano.",
        "relations": {
            "broader": [
                "AI Systems"
            ],
            "narrower": [
                "Text Classification",
                "Machine Translation"
            ],
            "related": [
                "Speech Recognition"
            ]
        },
        "variants": [
            "NLP"
        ],
        "sources": [
            {
                "name": "ISO/IEC 22989:2022",
                "url": "https://www.iso.org/standard/77465.html"
            }
        ],
        "area_semantica": "tecnico-operativa"
    },
    {
        "id": "TECH004",
        "term_en": "Computer Vision",
        "term_it": "Visione Artificiale",
        "definition_en": "AI methods enabling computers to interpret and process visual information from the environment.",
        "definition_it": "Metodi di IA che consentono ai computer di interpretare e elaborare informazioni visive dall'ambiente.",
        "relations": {
            "broader": [
                "AI Systems"
            ],
            "narrower": [
                "Image Recognition",
                "Object Detection"
            ],
            "related": [
                "Deep Learning"
            ]
        },
        "variants": [],
        "sources": [
            {
                "name": "ISO/IEC 22989:2022",
                "url": "https://www.iso.org/standard/77465.html"
            }
        ],
        "area_semantica": "tecnico-operativa"
    },
    {
        "id": "TECH005",
        "term_en": "Reinforcement Learning",
        "term_it": "Apprendimento per Rinforzo",
        "definition_en": "A learning method where agents learn to make decisions by trial and error to maximize cumulative reward.",
        "definition_it": "Un metodo di apprendimento in cui gli agenti imparano a prendere decisioni tramite prove ed errori per massimizzare la ricompensa cumulativa.",
        "relations": {
            "broader": [
                "Machine Learning"
            ],
            "narrower": [
                "Q-Learning",
                "Policy Gradient Methods"
            ],
            "related": [
                "Autonomous Systems"
            ]
        },
        "variants": [
            "RL"
        ],
        "sources": [
            {
                "name": "ISO/IEC 22989:2022",
                "url": "https://www.iso.org/standard/77465.html"
            }
        ],
        "area_semantica": "tecnico-operativa"
    },
    {
        "id": "TECH006",
        "term_en": "Autonomous Systems",
        "term_it": "Sistemi Autonomi",
        "definition_en": "AI-enabled systems capable of performing tasks without continuous human intervention.",
        "definition_it": "Sistemi abilitati all'IA in grado di svolgere compiti senza intervento umano continuo.",
        "relations": {
            "broader": [
                "AI Systems"
            ],
            "narrower": [
                "Autonomous Vehicles",
                "Robotics"
            ],
            "related": [
                "Reinforcement Learning"
            ]
        },
        "variants": [],
        "sources": [
            {
                "name": "ISO/IEC 22989:2022",
                "url": "https://www.iso.org/standard/77465.html"
            }
        ],
        "area_semantica": "tecnico-operativa"
    },
    {
        "id": "TECH007",
        "term_en": "Explainability",
        "term_it": "Spiegabilità",
        "definition_en": "Ability of AI systems to provide understandable explanations for their outputs and decisions.",
        "definition_it": "Capacità dei sistemi IA di fornire spiegazioni comprensibili sui propri output e decisioni.",
        "relations": {
            "broader": [
                "Transparency"
            ],
            "narrower": [
                "Local Explainability",
                "Global Explainability"
            ],
            "related": [
                "Accountability"
            ]
        },
        "variants": [
            "XAI"
        ],
        "sources": [
            {
                "name": "ISO/IEC 23894:2023",
                "url": "https://www.iso.org/standard/82684.html"
            }
        ],
        "area_semantica": "tecnico-operativa"
    },
    {
        "id": "TECH008",
        "term_en": "AI Systems",
        "term_it": "Sistemi IA",
        "definition_en": "Integrated AI applications combining algorithms, data, and computing resources to perform tasks.",
        "definition_it": "Applicazioni IA integrate che combinano algoritmi, dati e risorse computazionali per svolgere compiti.",
        "relations": {
            "broader": [
                "Artificial Intelligence"
            ],
            "narrower": [
                "Machine Learning",
                "Computer Vision"
            ],
            "related": [
                "Deep Learning"
            ]
        },
        "variants": [],
        "sources": [
            {
                "name": "ISO/IEC 22989:2022",
                "url": "https://www.iso.org/standard/77465.html"
            }
        ],
        "area_semantica": "tecnico-operativa"
    },
    {
        "id": "TECH009",
        "term_en": "Neural Networks",
        "term_it": "Reti Neurali",
        "definition_en": "Computational models inspired by biological neural networks to recognize patterns and solve problems.",
        "definition_it": "Modelli computazionali ispirati alle reti neurali biologiche per riconoscere schemi e risolvere problemi.",
        "relations": {
            "broader": [
                "Machine Learning"
            ],
            "narrower": [
                "CNN",
                "RNN"
            ],
            "related": [
                "Deep Learning"
            ]
        },
        "variants": [
            "ANN"
        ],
        "sources": [
            {
                "name": "ISO/IEC 22989:2022",
                "url": "https://www.iso.org/standard/77465.html"
            }
        ],
        "area_semantica": "tecnico-operativa"
    },
    {
        "id": "TECH010",
        "term_en": "Robotics",
        "term_it": "Robotica",
        "definition_en": "Field of engineering focused on designing, building, and operating robots, often using AI for autonomy.",
        "definition_it": "Campo dell'ingegneria focalizzato sulla progettazione, costruzione e gestione di robot, spesso utilizzando l'IA per l'autonomia.",
        "relations": {
            "broader": [
                "Autonomous Systems"
            ],
            "narrower": [],
            "related": [
                "Machine Learning"
            ]
        },
        "variants": [],
        "sources": [
            {
                "name": "ISO/IEC 22989:2022",
                "url": "https://www.iso.org/standard/77465.html"
            }
        ],
        "area_semantica": "tecnico-operativa"
    },
    {
        "id": "PHIL001",
        "term_en": "Autonomy",
        "term_it": "Autonomia",
        "definition_en": "The capacity of an AI system to operate and make decisions without human intervention.",
        "definition_it": "La capacità di un sistema IA di operare e prendere decisioni senza intervento umano.",
        "relations": {
            "broader": [
                "Agency"
            ],
            "narrower": [
                "Moral Autonomy in AI"
            ],
            "related": [
                "Ethics",
                "Accountability"
            ]
        },
        "variants": [
            "Self-governance"
        ],
        "sources": [
            {
                "name": "GPAI Codes of Practice",
                "url": "https://gpai.ai/"
            }
        ],
        "area_semantica": "concettuale-filosofica"
    },
    {
        "id": "PHIL002",
        "term_en": "Ethics",
        "term_it": "Etica",
        "definition_en": "Philosophical study of moral principles guiding the development, deployment, and societal impact of AI.",
        "definition_it": "Studio filosofico dei principi morali che guidano lo sviluppo e l'uso dell'IA.",
        "relations": {
            "broader": [
                "Philosophy"
            ],
            "narrower": [
                "AI Ethics",
                "Machine Ethics"
            ],
            "related": [
                "Autonomy"
            ]
        },
        "variants": [],
        "sources": [
            {
                "name": "GPAI Codes of Practice",
                "url": "https://gpai.ai/"
            }
        ],
        "area_semantica": "concettuale-filosofica"
    },
    {
        "id": "PHIL003",
        "term_en": "Agency",
        "term_it": "Agenzialità",
        "definition_en": "Ability of an AI system to act intentionally and make decisions affecting outcomes.",
        "definition_it": "Capacità di un sistema IA di agire intenzionalmente e prendere decisioni che influenzano i risultati.",
        "relations": {
            "broader": [
                "AI Philosophy"
            ],
            "narrower": [
                "Autonomy"
            ],
            "related": [
                "Ethics"
            ]
        },
        "variants": [],
        "sources": [
            {
                "name": "GPAI Codes of Practice",
                "url": "https://gpai.ai/"
            },
            {
                "name": "ISO/IEC 22989:2022",
                "url": "https://www.iso.org/standard/77465.html"
            }
        ],
        "area_semantica": "concettuale-filosofica"
    },
    {
        "id": "PHIL004",
        "term_en": "Moral Responsibility",
        "term_it": "Responsabilità morale",
        "definition_en": "Concept of assigning ethical accountability for AI system actions to humans or organizations.",
        "definition_it": "Concetto di assegnare responsabilità etica delle azioni dei sistemi IA a esseri umani o organizzazioni.",
        "relations": {
            "broader": [
                "Ethics"
            ],
            "narrower": [],
            "related": [
                "Autonomy",
                "Accountability"
            ]
        },
        "variants": [],
        "sources": [
            {
                "name": "GPAI Codes of Practice",
                "url": "https://gpai.ai/"
            }
        ],
        "area_semantica": "concettuale-filosofica"
    },
    {
        "id": "PHIL005",
        "term_en": "Transparency",
        "term_it": "Trasparenza concettuale",
        "definition_en": "Philosophical principle that AI operations and decisions should be understandable to humans.",
        "definition_it": "Principio filosofico secondo cui le operazioni e decisioni dell'IA dovrebbero essere comprensibili agli esseri umani.",
        "relations": {
            "broader": [
                "Ethics"
            ],
            "narrower": [
                "Explainability"
            ],
            "related": [
                "Accountability"
            ]
        },
        "variants": [],
        "sources": [
            {
                "name": "GPAI Codes of Practice",
                "url": "https://gpai.ai/"
            }
        ],
        "area_semantica": "concettuale-filosofica"
    },
    {
        "id": "PHIL006",
        "term_en": "Fairness",
        "term_it": "Equità concettuale",
        "definition_en": "Ethical principle that AI should operate without unfair bias or discrimination.",
        "definition_it": "Principio etico secondo cui l'IA dovrebbe operare senza bias o discriminazioni ingiustificate.",
        "relations": {
            "broader": [
                "Ethics"
            ],
            "narrower": [],
            "related": [
                "Bias Mitigation"
            ]
        },
        "variants": [],
        "sources": [
            {
                "name": "GPAI Codes of Practice",
                "url": "https://gpai.ai/"
            },
            {
                "name": "ISO/IEC 23894:2023",
                "url": "https://www.iso.org/standard/82684.html"
            }
        ],
        "area_semantica": "concettuale-filosofica"
    },
    {
        "id": "PHIL007",
        "term_en": "Accountability",
        "term_it": "Responsabilità concettuale",
        "definition_en": "Ethical principle that humans or organizations must answer for AI outcomes.",
        "definition_it": "Principio etico secondo cui esseri umani o organizzazioni devono rispondere dei risultati dell'IA.",
        "relations": {
            "broader": [
                "Ethics"
            ],
            "narrower": [],
            "related": [
                "Transparency",
                "Moral Responsibility"
            ]
        },
        "variants": [],
        "sources": [
            {
                "name": "GPAI Codes of Practice",
                "url": "https://gpai.ai/"
            }
        ],
        "area_semantica": "concettuale-filosofica"
    },
    {
        "id": "PHIL008",
        "term_en": "Privacy",
        "term_it": "Privacy concettuale",
        "definition_en": "Philosophical concern regarding the protection of personal data in AI systems.",
        "definition_it": "Preoccupazione filosofica relativa alla protezione dei dati personali nei sistemi IA.",
        "relations": {
            "broader": [
                "Ethics"
            ],
            "narrower": [
                "Data Protection"
            ],
            "related": [
                "Fairness"
            ]
        },
        "variants": [],
        "sources": [
            {
                "name": "GPAI Codes of Practice",
                "url": "https://gpai.ai/"
            },
            {
                "name": "GDPR 679/2016",
                "url": "https://eur-lex.europa.eu/eli/reg/2016/679/oj"
            }
        ],
        "area_semantica": "concettuale-filosofica"
    },
    {
        "id": "PHIL009",
        "term_en": "Moral Agency",
        "term_it": "Agenzialità morale",
        "definition_en": "Capacity of AI systems to be considered capable of moral decision-making.",
        "definition_it": "Capacità dei sistemi IA di essere considerati in grado di prendere decisioni morali.",
        "relations": {
            "broader": [
                "Agency"
            ],
            "narrower": [],
            "related": [
                "Autonomy",
                "Ethics"
            ]
        },
        "variants": [],
        "sources": [
            {
                "name": "GPAI Codes of Practice",
                "url": "https://gpai.ai/"
            }
        ],
        "area_semantica": "concettuale-filosofica"
    },
    {
        "id": "PHIL010",
        "term_en": "Emergent Intelligence",
        "term_it": "Intelligenza emergente",
        "definition_en": "The phenomenon where complex intelligent behavior arises from simpler AI components.",
        "definition_it": "Fenomeno in cui comportamenti intelligenti complessi emergono da componenti IA più semplici.",
        "relations": {
            "broader": [
                "Artificial Intelligence"
            ],
            "narrower": [],
            "related": [
                "Autonomy",
                "Agency"
            ]
        },
        "variants": [
            "Emergent AI"
        ],
        "sources": [
            {
                "name": "ISO/IEC 22989:2022",
                "url": "https://www.iso.org/standard/77465.html"
            },
            {
                "name": "GPAI Codes of Practice",
                "url": "https://gpai.ai/"
            }
        ],
        "area_semantica": "concettuale-filosofica"
    },
    {
        "id": "CUST031",
        "term_it": "Termine",
        "term_en": "Termine",
        "definition_it": "def",
        "definition_en": "def",
        "variants": [
            "other"
        ],
        "relations": {
            "related": [
                "rel"
            ]
        },
        "sources": [
            {
                "name": "reg"
            }
        ]
    },
    {
        "id": "CUST032",
        "term_it": "termine",
        "term_en": "termine",
        "definition_it": "def",
        "definition_en": "def",
        "variants": [
            "other"
        ],
        "relations": {
            "related": [
                "yess"
            ]
        },
        "sources": [
            {
                "name": "reg"
            }
        ]
    }
]